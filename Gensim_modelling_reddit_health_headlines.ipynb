{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from scipy import sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/top_health_posts.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congresswoman forces CDC to agree to offer fre...</td>\n",
       "      <td>1735</td>\n",
       "      <td>fhszdr</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://losangeles.cbslocal.com/2020/03/12/oc-...</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.584097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'I had all symptoms of Coronavirus. I could ha...</td>\n",
       "      <td>1647</td>\n",
       "      <td>fijk9f</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://www.telegraph.co.uk/news/2020/03/14/ha...</td>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.584227e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The first coronavirus case in the U.S. and Sou...</td>\n",
       "      <td>1602</td>\n",
       "      <td>fl9r23</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://www.reuters.com/article/us-health-coro...</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.584652e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As coronavirus spreads, the people who prepare...</td>\n",
       "      <td>1409</td>\n",
       "      <td>fdwr56</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://www.washingtonpost.com/national/as-cor...</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.583451e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who intentionally spread coronavirus cou...</td>\n",
       "      <td>1273</td>\n",
       "      <td>for03u</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://www.politico.com/news/2020/03/24/coron...</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.585175e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Drive-thru coronavirus testing site in Denver ...</td>\n",
       "      <td>1054</td>\n",
       "      <td>fj1leg</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://www.denverpost.com/2020/03/14/colorado...</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.584309e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Seattle lab uncovered Washington's coronavir...</td>\n",
       "      <td>1035</td>\n",
       "      <td>fi47nl</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://theweek.com/speedreads/901405/seattle-...</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.584153e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Coronavirus can live on surfaces for up to 3 d...</td>\n",
       "      <td>995</td>\n",
       "      <td>fh5t03</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://ktla.com/news/coronavirus/coronavirus-...</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.583995e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A coronavirus patient refused to quarantine, s...</td>\n",
       "      <td>991</td>\n",
       "      <td>fk8r7f</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://www.cnn.com/2020/03/17/us/kentucky-ref...</td>\n",
       "      <td>163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.584493e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alibaba's Jack Ma Sends Boxes of Coronavirus T...</td>\n",
       "      <td>951</td>\n",
       "      <td>fjkouq</td>\n",
       "      <td>Health</td>\n",
       "      <td>https://time.com/5803791/jack-ma-alibaba-coron...</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.584393e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id subreddit  \\\n",
       "0  Congresswoman forces CDC to agree to offer fre...   1735  fhszdr    Health   \n",
       "1  'I had all symptoms of Coronavirus. I could ha...   1647  fijk9f    Health   \n",
       "2  The first coronavirus case in the U.S. and Sou...   1602  fl9r23    Health   \n",
       "3  As coronavirus spreads, the people who prepare...   1409  fdwr56    Health   \n",
       "4  Those who intentionally spread coronavirus cou...   1273  for03u    Health   \n",
       "5  Drive-thru coronavirus testing site in Denver ...   1054  fj1leg    Health   \n",
       "6  A Seattle lab uncovered Washington's coronavir...   1035  fi47nl    Health   \n",
       "7  Coronavirus can live on surfaces for up to 3 d...    995  fh5t03    Health   \n",
       "8  A coronavirus patient refused to quarantine, s...    991  fk8r7f    Health   \n",
       "9  Alibaba's Jack Ma Sends Boxes of Coronavirus T...    951  fjkouq    Health   \n",
       "\n",
       "                                                 url  num_comments  body  \\\n",
       "0  https://losangeles.cbslocal.com/2020/03/12/oc-...            58   NaN   \n",
       "1  https://www.telegraph.co.uk/news/2020/03/14/ha...           170   NaN   \n",
       "2  https://www.reuters.com/article/us-health-coro...           114   NaN   \n",
       "3  https://www.washingtonpost.com/national/as-cor...           132   NaN   \n",
       "4  https://www.politico.com/news/2020/03/24/coron...            83   NaN   \n",
       "5  https://www.denverpost.com/2020/03/14/colorado...            95   NaN   \n",
       "6  https://theweek.com/speedreads/901405/seattle-...            45   NaN   \n",
       "7  https://ktla.com/news/coronavirus/coronavirus-...            86   NaN   \n",
       "8  https://www.cnn.com/2020/03/17/us/kentucky-ref...           163   NaN   \n",
       "9  https://time.com/5803791/jack-ma-alibaba-coron...            44   NaN   \n",
       "\n",
       "        created  \n",
       "0  1.584097e+09  \n",
       "1  1.584227e+09  \n",
       "2  1.584652e+09  \n",
       "3  1.583451e+09  \n",
       "4  1.585175e+09  \n",
       "5  1.584309e+09  \n",
       "6  1.584153e+09  \n",
       "7  1.583995e+09  \n",
       "8  1.584493e+09  \n",
       "9  1.584393e+09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove unused columns\n",
    "df = df.drop(columns= ['score', 'id', 'url', 'num_comments', 'body', 'created','subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congresswoman forces CDC to agree to offer fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'I had all symptoms of Coronavirus. I could ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The first coronavirus case in the U.S. and Sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As coronavirus spreads, the people who prepare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who intentionally spread coronavirus cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Drive-thru coronavirus testing site in Denver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Seattle lab uncovered Washington's coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Coronavirus can live on surfaces for up to 3 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A coronavirus patient refused to quarantine, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alibaba's Jack Ma Sends Boxes of Coronavirus T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  Congresswoman forces CDC to agree to offer fre...\n",
       "1  'I had all symptoms of Coronavirus. I could ha...\n",
       "2  The first coronavirus case in the U.S. and Sou...\n",
       "3  As coronavirus spreads, the people who prepare...\n",
       "4  Those who intentionally spread coronavirus cou...\n",
       "5  Drive-thru coronavirus testing site in Denver ...\n",
       "6  A Seattle lab uncovered Washington's coronavir...\n",
       "7  Coronavirus can live on surfaces for up to 3 d...\n",
       "8  A coronavirus patient refused to quarantine, s...\n",
       "9  Alibaba's Jack Ma Sends Boxes of Coronavirus T..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty cells\n",
    "import numpy as np\n",
    "df['title'] = df['title'].replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congresswoman forces CDC to agree to offer fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had all symptoms of Coronavirus I could have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The first coronavirus case in the US and South...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As coronavirus spreads the people who prepare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who intentionally spread coronavirus cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>More than 140 nursing homes have reported coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>â€˜Heâ€™s gonna get us all killedâ€™ sense of unease...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Trump berates NBCs Peter Alexander over corona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Coronavirus death estimates now reduced by 95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>How To Stay Safe From Coronavirus ðŸ˜¯</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title\n",
       "0    Congresswoman forces CDC to agree to offer fre...\n",
       "1    I had all symptoms of Coronavirus I could have...\n",
       "2    The first coronavirus case in the US and South...\n",
       "3    As coronavirus spreads the people who prepare ...\n",
       "4    Those who intentionally spread coronavirus cou...\n",
       "..                                                 ...\n",
       "325  More than 140 nursing homes have reported coro...\n",
       "326  â€˜Heâ€™s gonna get us all killedâ€™ sense of unease...\n",
       "327  Trump berates NBCs Peter Alexander over corona...\n",
       "328      Coronavirus death estimates now reduced by 95\n",
       "329                How To Stay Safe From Coronavirus ðŸ˜¯\n",
       "\n",
       "[330 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect docs as array\n",
    "docs = array(df['title'])\n",
    "print(len(docs))\n",
    "print(type(docs))\n",
    "type(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords function\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "# preprocessing\n",
    "def docs_preprocessor(docs):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for idx in range(len(docs)):\n",
    "        docs[idx] = docs[idx].lower() #convert to lowercase\n",
    "        docs[idx] = tokenizer.tokenize(docs[idx]) #split into words\n",
    "    \n",
    "    # remove stopwords\n",
    "    docs = [[token for token in doc if token not in stopwords.words('english')] for doc in docs]\n",
    "    \n",
    "    # remove numbers\n",
    "    docs = [[token for token in doc if not token.isdigit()] for doc in docs]\n",
    "    \n",
    "    # remove words < 1 character\n",
    "    docs = [[token for token in doc if len(token) > 3] for doc in docs]\n",
    "    \n",
    "    # lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs_preprocessor(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comput bigrams/trigrams\n",
    "from gensim.models import Phrases\n",
    "# add bigrams and trigrams to docs - only ones that appear 10 times or more\n",
    "bigram = Phrases(docs, min_count=10)\n",
    "trigram = Phrases(bigram[docs])\n",
    "\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            #token is a bigram - add to doc\n",
    "            docs[idx].append(token)\n",
    "    for token in trigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            #token is trigram - add to doc\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in initial docs: 1432\n",
      "Number of unique words after removing rare and common words: 29\n"
     ]
    }
   ],
   "source": [
    "# remove rare and common tokens\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# create a dictionary representation of the documents\n",
    "dictionary = Dictionary(docs)\n",
    "print(f\"Number of unique words in initial docs: {len(dictionary)}\")\n",
    "\n",
    "# filter out words that occur in less than 10 or more than 20%\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.2)\n",
    "print(f\"Number of unique words after removing rare and common words: {len(dictionary)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 29\n",
      "Number of documents: 330\n"
     ]
    }
   ],
   "source": [
    "#vectorize - get a 'bag-of-words' representation \n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print(f\"Number of unique tokens: {len(dictionary)}\")\n",
    "print(f\"Number of documents: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.89 s, sys: 12 ms, total: 1.9 s\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "# train LDA model\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "#set training params\n",
    "num_topics = 4\n",
    "chunksize = 500 # size of doc each pass examines\n",
    "passes = 20 # num of passes\n",
    "iterations = 400\n",
    "eval_every = 1 # do not eval model perplexity\n",
    "\n",
    "#make index to word dict\n",
    "temp = dictionary[0] # load dict\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "# track the CPU time and let the model run\n",
    "%time model = LdaModel(corpus=corpus, id2word=id2word, chunksize=chunksize, \\\n",
    "                      alpha='auto', eta='auto', \\\n",
    "                      iterations=iterations, num_topics=num_topics, \\\n",
    "                      passes=passes, eval_every=eval_every)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el9909449368858405824189558\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el9909449368858405824189558_data = {\"mdsDat\": {\"x\": [-0.35592787327801384, 0.13260934406819552, 0.10709581608356535, 0.1162227131262534], \"y\": [0.013293631027083495, 0.23548671758986822, -0.26490511952710993, 0.016124770910158164], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [29.566665649414062, 24.845487594604492, 23.31792640686035, 22.269920349121094]}, \"tinfo\": {\"Term\": [\"case\", \"covid19\", \"test\", \"people\", \"say\", \"testing\", \"spread\", \"mask\", \"state\", \"outbreak\", \"world\", \"positive\", \"health\", \"could\", \"risk\", \"doctor\", \"first\", \"study\", \"drug\", \"patient\", \"hospital\", \"pandemic\", \"disease\", \"week\", \"virus\", \"need\", \"american\", \"death\", \"home\", \"test\", \"people\", \"mask\", \"state\", \"positive\", \"first\", \"american\", \"death\", \"week\", \"home\", \"pandemic\", \"need\", \"study\", \"doctor\", \"risk\", \"drug\", \"virus\", \"world\", \"disease\", \"case\", \"outbreak\", \"spread\", \"hospital\", \"could\", \"testing\", \"patient\", \"health\", \"say\", \"covid19\", \"covid19\", \"risk\", \"doctor\", \"study\", \"drug\", \"disease\", \"patient\", \"pandemic\", \"home\", \"death\", \"health\", \"virus\", \"need\", \"week\", \"american\", \"world\", \"outbreak\", \"first\", \"spread\", \"positive\", \"hospital\", \"testing\", \"state\", \"mask\", \"say\", \"could\", \"people\", \"test\", \"case\", \"case\", \"testing\", \"spread\", \"hospital\", \"health\", \"need\", \"could\", \"home\", \"death\", \"american\", \"virus\", \"drug\", \"week\", \"study\", \"first\", \"world\", \"doctor\", \"risk\", \"outbreak\", \"disease\", \"positive\", \"pandemic\", \"mask\", \"state\", \"patient\", \"say\", \"covid19\", \"people\", \"test\", \"say\", \"outbreak\", \"world\", \"week\", \"virus\", \"could\", \"patient\", \"pandemic\", \"need\", \"hospital\", \"disease\", \"home\", \"american\", \"death\", \"health\", \"study\", \"drug\", \"risk\", \"doctor\", \"first\", \"positive\", \"spread\", \"testing\", \"state\", \"mask\", \"people\", \"test\", \"covid19\", \"case\"], \"Freq\": [32.0, 26.0, 26.0, 26.0, 19.0, 16.0, 16.0, 18.0, 18.0, 13.0, 12.0, 15.0, 22.0, 19.0, 12.0, 12.0, 13.0, 11.0, 11.0, 18.0, 16.0, 16.0, 13.0, 11.0, 12.0, 10.0, 12.0, 14.0, 13.0, 26.118778228759766, 26.109447479248047, 17.4699764251709, 17.465084075927734, 14.60899829864502, 12.636945724487305, 8.974071502685547, 6.976537704467773, 3.7056992053985596, 3.059908866882324, 0.4197090268135071, 0.2533416748046875, 0.24434177577495575, 0.2630956768989563, 0.26248881220817566, 0.24004517495632172, 0.24288688600063324, 0.24279361963272095, 0.24615563452243805, 0.6015498638153076, 0.24244455993175507, 0.28207385540008545, 0.25136610865592957, 0.3040713965892792, 0.24741318821907043, 0.2452928125858307, 0.29472267627716064, 0.24943192303180695, 0.2526644170284271, 26.124576568603516, 11.322733879089355, 11.321091651916504, 10.411161422729492, 10.390385627746582, 8.654614448547363, 10.446158409118652, 9.311572074890137, 4.394143581390381, 4.111097812652588, 6.271308422088623, 2.9491002559661865, 0.23433537781238556, 0.2332337200641632, 0.24239037930965424, 0.23443181812763214, 0.23241783678531647, 0.23363544046878815, 0.2604263722896576, 0.23372310400009155, 0.235330730676651, 0.23268507421016693, 0.25036177039146423, 0.23486219346523285, 0.24265536665916443, 0.23993951082229614, 0.2373039871454239, 0.23684118688106537, 0.23273588716983795, 31.26005744934082, 15.450286865234375, 15.386935234069824, 10.76201057434082, 15.029946327209473, 5.937966823577881, 7.129454135894775, 2.2657477855682373, 1.8928419351577759, 1.4509674310684204, 1.3430663347244263, 0.26830995082855225, 0.2448716014623642, 0.2385817915201187, 0.27702170610427856, 0.24518784880638123, 0.2408326417207718, 0.23809783160686493, 0.24028046429157257, 0.23868755996227264, 0.2458312213420868, 0.2502407133579254, 0.2587427794933319, 0.24750082194805145, 0.24547699093818665, 0.2557072341442108, 0.26780298352241516, 0.24025364220142365, 0.2396954447031021, 18.869388580322266, 12.36570930480957, 11.424813270568848, 7.120580196380615, 7.610849380493164, 12.073463439941406, 7.664346218109131, 6.766102313995361, 3.960691452026367, 4.829866886138916, 3.873852252960205, 3.4393506050109863, 1.731350064277649, 1.2104785442352295, 1.050899624824524, 0.23768159747123718, 0.23363953828811646, 0.2353048324584961, 0.2336827963590622, 0.25919580459594727, 0.2368350327014923, 0.23609301447868347, 0.23564699292182922, 0.2384154349565506, 0.23823851346969604, 0.24455049633979797, 0.23648548126220703, 0.23440004885196686, 0.24911528825759888], \"Total\": [32.0, 26.0, 26.0, 26.0, 19.0, 16.0, 16.0, 18.0, 18.0, 13.0, 12.0, 15.0, 22.0, 19.0, 12.0, 12.0, 13.0, 11.0, 11.0, 18.0, 16.0, 16.0, 13.0, 11.0, 12.0, 10.0, 12.0, 14.0, 13.0, 26.831798553466797, 26.83155632019043, 18.201820373535156, 18.20136260986328, 15.325387954711914, 13.40679931640625, 12.39877986907959, 14.190956115722656, 11.304384231567383, 13.159151077270508, 16.747623443603516, 10.386335372924805, 11.131766319274902, 12.05870246887207, 12.058625221252441, 11.132380485534668, 12.145902633666992, 12.147226333618164, 13.013309478759766, 32.34346008300781, 13.080852508544922, 16.165529251098633, 16.078575134277344, 19.746929168701172, 16.166032791137695, 18.601274490356445, 22.64687728881836, 19.617183685302734, 26.879444122314453, 26.879444122314453, 12.058625221252441, 12.05870246887207, 11.131766319274902, 11.132380485534668, 13.013309478759766, 18.601274490356445, 16.747623443603516, 13.159151077270508, 14.190956115722656, 22.64687728881836, 12.145902633666992, 10.386335372924805, 11.304384231567383, 12.39877986907959, 12.147226333618164, 13.080852508544922, 13.40679931640625, 16.165529251098633, 15.325387954711914, 16.078575134277344, 16.166032791137695, 18.20136260986328, 18.201820373535156, 19.617183685302734, 19.746929168701172, 26.83155632019043, 26.831798553466797, 32.34346008300781, 32.34346008300781, 16.166032791137695, 16.165529251098633, 16.078575134277344, 22.64687728881836, 10.386335372924805, 19.746929168701172, 13.159151077270508, 14.190956115722656, 12.39877986907959, 12.145902633666992, 11.132380485534668, 11.304384231567383, 11.131766319274902, 13.40679931640625, 12.147226333618164, 12.05870246887207, 12.058625221252441, 13.080852508544922, 13.013309478759766, 15.325387954711914, 16.747623443603516, 18.201820373535156, 18.20136260986328, 18.601274490356445, 19.617183685302734, 26.879444122314453, 26.83155632019043, 26.831798553466797, 19.617183685302734, 13.080852508544922, 12.147226333618164, 11.304384231567383, 12.145902633666992, 19.746929168701172, 18.601274490356445, 16.747623443603516, 10.386335372924805, 16.078575134277344, 13.013309478759766, 13.159151077270508, 12.39877986907959, 14.190956115722656, 22.64687728881836, 11.131766319274902, 11.132380485534668, 12.058625221252441, 12.05870246887207, 13.40679931640625, 15.325387954711914, 16.165529251098633, 16.166032791137695, 18.20136260986328, 18.201820373535156, 26.83155632019043, 26.831798553466797, 26.879444122314453, 32.34346008300781], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.6967999935150146, -1.697100043296814, -2.098900079727173, -2.0992000102996826, -2.2778000831604004, -2.422800064086914, -2.7651000022888184, -3.016900062561035, -3.6494998931884766, -3.8410000801086426, -5.827600002288818, -6.332399845123291, -6.368599891662598, -6.2947001457214355, -6.296999931335449, -6.386300086975098, -6.374599933624268, -6.375, -6.361199855804443, -5.467700004577637, -6.376399993896484, -6.224999904632568, -6.3403000831604, -6.149899959564209, -6.356100082397461, -6.364699840545654, -6.181099891662598, -6.3480000495910645, -6.335100173950195, -1.5226000547409058, -2.358599901199341, -2.358799934387207, -2.4426000118255615, -2.4446001052856445, -2.6273999214172363, -2.439199924468994, -2.5541999340057373, -3.3052000999450684, -3.371799945831299, -2.94950008392334, -3.7039999961853027, -6.236499786376953, -6.241199970245361, -6.202700138092041, -6.236000061035156, -6.244699954986572, -6.2393999099731445, -6.130899906158447, -6.239099979400635, -6.2322001457214355, -6.243500232696533, -6.170300006866455, -6.2342000007629395, -6.201600074768066, -6.212800025939941, -6.223899841308594, -6.225800037384033, -6.243299961090088, -1.2797000408172607, -1.9844000339508057, -1.9884999990463257, -2.3459999561309814, -2.01200008392334, -2.9405999183654785, -2.7578001022338867, -3.904099941253662, -4.083899974822998, -4.349800109863281, -4.427000045776367, -6.037600040435791, -6.129000186920166, -6.15500020980835, -6.00570011138916, -6.127699851989746, -6.145599842071533, -6.157100200653076, -6.147900104522705, -6.154600143432617, -6.125100135803223, -6.1072998046875, -6.07390022277832, -6.118299961090088, -6.126500129699707, -6.085700035095215, -6.0395002365112305, -6.148099899291992, -6.150400161743164, -1.7384999990463257, -2.161099910736084, -2.2402000427246094, -2.7130000591278076, -2.646399974822998, -2.184999942779541, -2.639400005340576, -2.7641000747680664, -3.2995998859405518, -3.1012001037597656, -3.3217999935150146, -3.440700054168701, -4.127099990844727, -4.485000133514404, -4.626399993896484, -6.112800121307373, -6.130000114440918, -6.122900009155273, -6.129799842834473, -6.026199817657471, -6.116399765014648, -6.119500160217285, -6.121399879455566, -6.109799861907959, -6.110499858856201, -6.0843000411987305, -6.1178998947143555, -6.126699924468994, -6.065899848937988], \"loglift\": [29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.19159996509552, 1.1912000179290771, 1.1775000095367432, 1.1771999597549438, 1.1706000566482544, 1.1593999862670898, 0.8952999711036682, 0.5084999799728394, 0.10320000350475311, -0.2401999980211258, -2.467900037765503, -2.494999885559082, -2.6005001068115234, -2.6064999103546143, -2.608799934387207, -2.618299961090088, -2.6935999393463135, -2.6940999031066895, -2.7492001056671143, -2.7660999298095703, -2.7695999145507812, -2.829900026321411, -2.9398000240325928, -2.9549999237060547, -2.9611001014709473, -3.109999895095825, -3.123199939727783, -3.1465001106262207, -3.448499917984009, 1.3639999628067017, 1.3294999599456787, 1.3293999433517456, 1.325600028038025, 1.3235000371932983, 0.9846000075340271, 0.815500020980835, 0.8054999709129333, 0.2955999970436096, 0.15360000729560852, 0.10849999636411667, -0.023000000044703484, -2.3989999294281006, -2.4883999824523926, -2.54229998588562, -2.5552000999450684, -2.6379001140594482, -2.6572999954223633, -2.73580002784729, -2.790600061416626, -2.8317999839782715, -2.8485000133514404, -2.893899917602539, -2.9577999114990234, -3.0, -3.017899990081787, -3.3355000019073486, -3.3375000953674316, -3.541800022125244, 1.4219000339508057, 1.4106999635696411, 1.406599998474121, 1.0544999837875366, 1.0460000038146973, 0.8967999815940857, 0.43720000982284546, -0.30329999327659607, -0.5586000084877014, -0.6894000172615051, -0.7461000084877014, -2.2695000171661377, -2.376300096511841, -2.386899948120117, -2.4235000610351562, -2.446899890899658, -2.4574999809265137, -2.468899965286255, -2.5411999225616455, -2.54259991645813, -2.6767001152038574, -2.7476000785827637, -2.797499895095825, -2.841900110244751, -2.871799945831299, -2.884200096130371, -3.152899980545044, -3.259700059890747, -3.26200008392334, 1.4630999565124512, 1.4457000494003296, 1.440600037574768, 1.0397000312805176, 1.034500002861023, 1.0098999738693237, 0.6152999997138977, 0.5956000089645386, 0.5378999710083008, 0.2992999851703644, 0.29019999504089355, 0.16009999811649323, -0.4668000042438507, -0.9596999883651733, -1.5684000253677368, -2.3447000980377197, -2.3619000911712646, -2.4347000122070312, -2.4416000843048096, -2.444000005722046, -2.6679999828338623, -2.7244999408721924, -2.7263998985290527, -2.8333001136779785, -2.8341000080108643, -3.196000099182129, -3.2295000553131104, -3.2402000427246094, -3.364300012588501]}, \"token.table\": {\"Topic\": [1, 3, 4, 1, 3, 3, 4, 2, 1, 2, 3, 4, 2, 4, 2, 2, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 3, 4, 4, 2, 4, 2, 4, 1, 1, 2, 4, 3, 1, 2, 1, 3, 2, 3, 4, 1, 4, 4], \"Freq\": [0.7258778810501099, 0.08065309375524521, 0.16130618751049042, 0.030918151140213013, 0.9584627151489258, 0.35448551177978516, 0.6076894402503967, 0.9672819375991821, 0.49327191710472107, 0.28186964988708496, 0.14093482494354248, 0.07046741247177124, 0.6915996074676514, 0.3073776066303253, 0.9122042655944824, 0.8982805013656616, 0.9696572422981262, 0.2649371922016144, 0.6623429656028748, 0.04415619745850563, 0.22797822952270508, 0.30397096276283264, 0.15198548138141632, 0.22797822952270508, 0.6841402053833008, 0.31097283959388733, 0.9339725375175476, 0.5776820778846741, 0.3851214051246643, 0.917371392250061, 0.5373896956443787, 0.4179697632789612, 0.5375975966453552, 0.43007805943489075, 0.9690082669258118, 0.9787680506706238, 0.9122101068496704, 0.9685386419296265, 0.9279003143310547, 0.9339960217475891, 0.89833003282547, 0.9689995050430298, 0.9278714060783386, 0.24699687957763672, 0.08233229070901871, 0.6586583256721497, 0.3538450002670288, 0.6192287802696228, 0.9055564999580383], \"Term\": [\"american\", \"american\", \"american\", \"case\", \"case\", \"could\", \"could\", \"covid19\", \"death\", \"death\", \"death\", \"death\", \"disease\", \"disease\", \"doctor\", \"drug\", \"first\", \"health\", \"health\", \"health\", \"home\", \"home\", \"home\", \"home\", \"hospital\", \"hospital\", \"mask\", \"need\", \"need\", \"outbreak\", \"pandemic\", \"pandemic\", \"patient\", \"patient\", \"people\", \"positive\", \"risk\", \"say\", \"spread\", \"state\", \"study\", \"test\", \"testing\", \"virus\", \"virus\", \"virus\", \"week\", \"week\", \"world\"]}, \"R\": 29, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 4, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el9909449368858405824189558\", ldavis_el9909449368858405824189558_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el9909449368858405824189558\", ldavis_el9909449368858405824189558_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el9909449368858405824189558\", ldavis_el9909449368858405824189558_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.355928  0.013294       1        1  29.566666\n",
       "1      0.132609  0.235487       2        1  24.845488\n",
       "3      0.107096 -0.264905       3        1  23.317926\n",
       "2      0.116223  0.016125       4        1  22.269920, topic_info=       Term       Freq      Total Category  logprob  loglift\n",
       "3      case  32.000000  32.000000  Default  29.0000  29.0000\n",
       "18  covid19  26.000000  26.000000  Default  28.0000  28.0000\n",
       "8      test  26.000000  26.000000  Default  27.0000  27.0000\n",
       "6    people  26.000000  26.000000  Default  26.0000  26.0000\n",
       "15      say  19.000000  19.000000  Default  25.0000  25.0000\n",
       "..      ...        ...        ...      ...      ...      ...\n",
       "14     mask   0.238239  18.201820   Topic4  -6.1105  -2.8341\n",
       "6    people   0.244550  26.831556   Topic4  -6.0843  -3.1960\n",
       "8      test   0.236485  26.831799   Topic4  -6.1179  -3.2295\n",
       "18  covid19   0.234400  26.879444   Topic4  -6.1267  -3.2402\n",
       "3      case   0.249115  32.343460   Topic4  -6.0659  -3.3643\n",
       "\n",
       "[145 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "0         1  0.725878  american\n",
       "0         3  0.080653  american\n",
       "0         4  0.161306  american\n",
       "3         1  0.030918      case\n",
       "3         3  0.958463      case\n",
       "4         3  0.354486     could\n",
       "4         4  0.607689     could\n",
       "18        2  0.967282   covid19\n",
       "22        1  0.493272     death\n",
       "22        2  0.281870     death\n",
       "22        3  0.140935     death\n",
       "22        4  0.070467     death\n",
       "23        2  0.691600   disease\n",
       "23        4  0.307378   disease\n",
       "17        2  0.912204    doctor\n",
       "28        2  0.898281      drug\n",
       "5         1  0.969657     first\n",
       "16        2  0.264937    health\n",
       "16        3  0.662343    health\n",
       "16        4  0.044156    health\n",
       "26        1  0.227978      home\n",
       "26        2  0.303971      home\n",
       "26        3  0.151985      home\n",
       "26        4  0.227978      home\n",
       "19        3  0.684140  hospital\n",
       "19        4  0.310973  hospital\n",
       "14        1  0.933973      mask\n",
       "1         3  0.577682      need\n",
       "1         4  0.385121      need\n",
       "11        4  0.917371  outbreak\n",
       "24        2  0.537390  pandemic\n",
       "24        4  0.417970  pandemic\n",
       "13        2  0.537598   patient\n",
       "13        4  0.430078   patient\n",
       "6         1  0.969008    people\n",
       "10        1  0.978768  positive\n",
       "27        2  0.912210      risk\n",
       "15        4  0.968539       say\n",
       "7         3  0.927900    spread\n",
       "20        1  0.933996     state\n",
       "12        2  0.898330     study\n",
       "8         1  0.969000      test\n",
       "2         3  0.927871   testing\n",
       "25        2  0.246997     virus\n",
       "25        3  0.082332     virus\n",
       "25        4  0.658658     virus\n",
       "9         1  0.353845      week\n",
       "9         4  0.619229      week\n",
       "21        4  0.905556     world, R=29, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 4, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# split each doc into 2 parts\n",
    "df['tokens'] = docs\n",
    "docs1 = df['tokens'].apply(lambda l: l[:int0(len(l)/2)])\n",
    "docs2 = df['tokens'].apply(lambda l: l[int0(len(l)/2):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data using LDA model\n",
    "corpus1 = [dictionary.doc2bow(doc) for doc in docs1]\n",
    "corpus2 = [dictionary.doc2bow(doc) for doc in docs2]\n",
    "\n",
    "lda_corpus1 = model[corpus1]\n",
    "lda_corpus2 = model[corpus2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "#(LDA) matrix transformation of docs in the topic space\n",
    "def get_doc_topic_dist(model, corpus, kwords=False):\n",
    "    top_dist = []\n",
    "    keys = []\n",
    "\n",
    "    for d in corpus:\n",
    "        tmp = {i:0 for i in range(num_topics)}\n",
    "        tmp.update(dict(model[d]))\n",
    "        vals = list(OrderedDict(tmp).values())\n",
    "        top_dist += [array(vals)]\n",
    "        if kwords:\n",
    "            keys +- [arrays(vals).argmax()]\n",
    "    return array(top_dist), keys    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra similarity: cosine similarity for corresponding parts of a doc(higher is better):\n",
      "0.9696374\n",
      "Inter similarity: cosine similarity between random parts (lower is better):\n",
      "0.9603348\n"
     ]
    }
   ],
   "source": [
    "top_dist1, _ = get_doc_topic_dist(model, lda_corpus1)\n",
    "top_dist2, _ = get_doc_topic_dist(model, lda_corpus2)\n",
    "\n",
    "print(\"Intra similarity: cosine similarity for corresponding parts of a doc(higher is better):\")\n",
    "print(mean([cosine_similarity(c1.reshape(1, -1), c2.reshape(1, -1))[0][0] for c1,c2 in zip(top_dist1, top_dist2)]))\n",
    "\n",
    "random_pairs = np.random.randint(0, len(df['title']), size=(400, 2))\n",
    "\n",
    "print(\"Inter similarity: cosine similarity between random parts (lower is better):\")\n",
    "print(np.mean([cosine_similarity(top_dist1[i[0]].reshape(1, -1), top_dist2[i[1]].reshape(1, -1)) for i in random_pairs]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore frequent terms in topic\n",
    "def explore_topic(lda_model, topic_number, topn, output=True):\n",
    "    #prints formatted list of the topn terms\n",
    "    terms = []\n",
    "    for term, frequency in lda_model.show_topic(topic_number, topn=topn):\n",
    "        terms += [term]\n",
    "        if output:\n",
    "            print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "Topic 0 |---------------------\n",
      "\n",
      "test                 0.183\n",
      "people               0.183\n",
      "mask                 0.123\n",
      "state                0.123\n",
      "positive             0.103\n",
      "first                0.089\n",
      "american             0.063\n",
      "death                0.049\n",
      "week                 0.026\n",
      "home                 0.021\n",
      "Topic 1 |---------------------\n",
      "\n",
      "covid19              0.218\n",
      "risk                 0.095\n",
      "doctor               0.095\n",
      "patient              0.087\n",
      "study                0.087\n",
      "drug                 0.087\n",
      "pandemic             0.078\n",
      "disease              0.072\n",
      "health               0.052\n",
      "home                 0.037\n",
      "Topic 2 |---------------------\n",
      "\n",
      "say                  0.176\n",
      "outbreak             0.115\n",
      "could                0.112\n",
      "world                0.106\n",
      "patient              0.071\n",
      "virus                0.071\n",
      "week                 0.066\n",
      "pandemic             0.063\n",
      "hospital             0.045\n",
      "need                 0.037\n",
      "Topic 3 |---------------------\n",
      "\n",
      "case                 0.278\n",
      "testing              0.137\n",
      "spread               0.137\n",
      "health               0.134\n",
      "hospital             0.096\n",
      "could                0.063\n",
      "need                 0.053\n",
      "home                 0.020\n",
      "death                0.017\n",
      "american             0.013\n"
     ]
    }
   ],
   "source": [
    "topic_summaries = []\n",
    "print(u'{:20} {}'.format(u'term', u'frequency') + u'\\n')\n",
    "for i in range(num_topics):\n",
    "    print('Topic '+str(i)+' |---------------------\\n')\n",
    "    tmp = explore_topic(model,topic_number=i, topn=10, output=True )\n",
    "#     print tmp[:5]\n",
    "    topic_summaries += [tmp[:5]]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
